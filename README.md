# CalibrationPapers
Must-read papers on deep learning model calibration methods.

## Incentivize Calibration Loss

### Differentiable Calibration Loss
- arXiv 2021 [Soft Calibration Objectives for Neural Networks](https://arxiv.org/abs/2108.00106)
- ICML 2021 UDL Workshop [Meta-Calibration: Meta-Learning of Model Calibration Using Differentiable Expected Calibration Error](http://arxiv.org/abs/2106.09613)
- ICML 2018 [Trainable Calibration Measures For Neural Networks From Kernel Mean Embeddings](http://proceedings.mlr.press/v80/kumar18a/kumar18a.pdf)

### Novel Loss
- NeurIPS 2020 [Improving model calibration with accuracy versus uncertainty optimization](https://papers.nips.cc/paper/2020/file/d3d9446802a44259755d38e6d163e820-Paper.pdf)
- NeurIPS 2020 [Calibrating Deep Neural Networks using Focal Loss](https://proceedings.neurips.cc/paper/2020/file/aeb7b30ef1d024a76f21a1d40e30c302-Paper.pdf)
- NeurIPS 2019 [When Does Label Smoothing Help?](https://papers.nips.cc/paper/8717-when-does-label-smoothing-help.pdf)
- ICLR 2021 [EVALUATION OF NEURAL ARCHITECTURES TRAINED WITH SQUARE LOSS VS CROSS-ENTROPY IN CLASSIFICATION TASKS](https://openreview.net/forum?id=hsFN92eQEla)

## Post Hoc
- ICML 2017 [On calibration of modern neural networks](https://proceedings.mlr.press/v70/guo17a/guo17a.pdf)
- arXiv 2019 [Attended Temperature Scaling: A Practical Approach for Calibrating Deep Neural Networks](https://arxiv.org/abs/1810.11586)
- arXiv 2020 [Post-hoc Calibration of Neural Networks](https://arxiv.org/abs/2006.12807)
- NeurIPS 2019 [Beyond temperature scaling: Obtaining well-calibrated multiclass probabilities with Dirichlet calibration](https://papers.nips.cc/paper/9397-beyond-temperature-scaling-obtaining-well-calibrated-multi-class-probabilities-with-dirichlet-calibration.pdf)
- ECML/PKDD 2019 [Non-parametric Bayesian isotonic calibration: Fighting overconfidence in binary classification](https://ecmlpkdd2019.org/downloads/paper/587.pdf)
- AISTATS 2020 [Non-parametric calibration for classification](http://proceedings.mlr.press/v108/wenger20a/wenger20a.pdf)
- ICLR 2021 [Calibration of neural networks using splines](https://openreview.net/forum?id=eQe8DEWNN2W)

## Ensemble Multiple Prediction
- NeurIPS 2017 [Simple and scalable predictive uncertainty estimation using deep ensembles](https://papers.nips.cc/paper/7219-simple-and-scalable-predictive-uncertainty-estimation-using-deep-ensembles.pdf)
- ICLR 2020 [BatchEnsemble: an alternative approach to efficient ensemble and lifelong learning](https://openreview.net/pdf?id=Sklf1yrYDr)
- ICML 2020 [Efficient and scalable bayesian neural nets with rank-1 factors](http://proceedings.mlr.press/v119/dusenberry20a/dusenberry20a.pdf)
- ICML 2016 [Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning](http://proceedings.mlr.press/v48/gal16.html)

## New Calibration Metric
- NeurIPS 2019 [Verified uncertainty calibration](https://papers.nips.cc/paper/8635-verified-uncertainty-calibration)
- arXiv 2021 [Mitigating bias in calibration error estimation](https://arxiv.org/abs/2012.08668)
- AAAI 2015 [Obtaining Well Calibrated Probabilities Using Bayesian Binning](https://people.cs.pitt.edu/~milos/research/AAAI_Calibration.pdf)

## Application

### NLP
- NIPS 2015 [Calibrated Structured Prediction](https://papers.nips.cc/paper/5658-calibrated-structured-prediction)
- ACL 2018 [Confidence Modeling for Neural Semantic Parsing](https://aclanthology.org/P18-1069)
- ACL 2020 [Calibrating Structured Output Predictors for Natural Language Processing](https://aclanthology.org/2020.acl-main.188.pdf)
- ICML 2020 [Calibration, Entropy Rates, and Memory in Language Models](http://proceedings.mlr.press/v119/braverman20a/braverman20a.pdf)
- EMNLP 2019 [Improving Back-Translation with Uncertainty-based Confidence Estimation](http://nlp.csai.tsinghua.edu.cn/~ly/papers/D19-1073.pdf)
- ACL 2020 [On the Inference Calibration of Neural Machine Translation](https://aclanthology.org/2020.acl-main.278.pdf)
- EMNLP 2020 [Calibration of Pre-trained Transformers](https://aclanthology.org/2020.emnlp-main.21.pdf)
- EMNLP 2020 [Calibrated Language Model Fine-Tuning for In- and Out-of-Distribution Data](https://aclanthology.org/2020.emnlp-main.102.pdf)
- TACL 2020 [How Can We Know When Language Models Know? On the Calibration of Language Models for Question Answering](https://aclanthology.org/2020.tacl-1.28)
- arXiv 2021 [Calibrate Before Use: Improving Few-Shot Performance of Language Models](https://arxiv.org/abs/2102.09690)
- arXiv 2019 [ Calibration of encoder decoder models for neural machine translation](https://arxiv.org/abs/1903.00802)

